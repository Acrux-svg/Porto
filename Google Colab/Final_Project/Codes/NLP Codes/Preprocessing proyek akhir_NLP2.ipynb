{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7164310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64010530",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('hasil scraping10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dbfc0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['Datetime','Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "662dbea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-14 23:47:33+00:00</td>\n",
       "      <td>Pertama benarkah harga air bersih lebih mahal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-14 23:40:21+00:00</td>\n",
       "      <td>Minyak goreng, dll kapan ya turun harga :') \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-14 23:20:52+00:00</td>\n",
       "      <td>@detikcom Turun kan harga minyak goreng uae pa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-14 23:14:02+00:00</td>\n",
       "      <td>Berikut Strategi Supaya Harga Minyak Goreng Sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-14 22:48:49+00:00</td>\n",
       "      <td>@eg_nrs Selamat pagi Mih...\\n\\nMau tanya Mih,m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77952</th>\n",
       "      <td>2020-01-03 08:03:37+00:00</td>\n",
       "      <td>Waw Promo Superindo Periode 3-5 Januari 2020, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77953</th>\n",
       "      <td>2020-01-02 14:40:33+00:00</td>\n",
       "      <td>Abis mandi udah make skincare siap tidur\\nBapa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77954</th>\n",
       "      <td>2020-01-02 14:09:32+00:00</td>\n",
       "      <td>@bucinajateros @in_makiy @FOODFESS2 Ya, \\nharg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77955</th>\n",
       "      <td>2020-01-01 06:49:02+00:00</td>\n",
       "      <td>@Savianisaa Mahal bgt harga minyak goreng segi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77956</th>\n",
       "      <td>2020-01-01 04:27:02+00:00</td>\n",
       "      <td>1. Aku goreng daging dgn kunyit dlu. agak dh y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77957 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Datetime  \\\n",
       "0      2022-05-14 23:47:33+00:00   \n",
       "1      2022-05-14 23:40:21+00:00   \n",
       "2      2022-05-14 23:20:52+00:00   \n",
       "3      2022-05-14 23:14:02+00:00   \n",
       "4      2022-05-14 22:48:49+00:00   \n",
       "...                          ...   \n",
       "77952  2020-01-03 08:03:37+00:00   \n",
       "77953  2020-01-02 14:40:33+00:00   \n",
       "77954  2020-01-02 14:09:32+00:00   \n",
       "77955  2020-01-01 06:49:02+00:00   \n",
       "77956  2020-01-01 04:27:02+00:00   \n",
       "\n",
       "                                                    Text  \n",
       "0      Pertama benarkah harga air bersih lebih mahal ...  \n",
       "1      Minyak goreng, dll kapan ya turun harga :') \\n...  \n",
       "2         @detikcom Turun kan harga minyak goreng uae pa  \n",
       "3      Berikut Strategi Supaya Harga Minyak Goreng Sa...  \n",
       "4      @eg_nrs Selamat pagi Mih...\\n\\nMau tanya Mih,m...  \n",
       "...                                                  ...  \n",
       "77952  Waw Promo Superindo Periode 3-5 Januari 2020, ...  \n",
       "77953  Abis mandi udah make skincare siap tidur\\nBapa...  \n",
       "77954  @bucinajateros @in_makiy @FOODFESS2 Ya, \\nharg...  \n",
       "77955  @Savianisaa Mahal bgt harga minyak goreng segi...  \n",
       "77956  1. Aku goreng daging dgn kunyit dlu. agak dh y...  \n",
       "\n",
       "[77957 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3bef046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\users\\mocha\\anaconda3\\lib\\site-packages (1.7.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49a54ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\mocha\\anaconda3\\lib\\site-packages (4.19.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\mocha\\anaconda3\\lib\\site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mocha\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\mocha\\anaconda3\\lib\\site-packages (from transformers) (3.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mocha\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mocha\\anaconda3\\lib\\site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\mocha\\anaconda3\\lib\\site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\mocha\\anaconda3\\lib\\site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: requests in c:\\users\\mocha\\anaconda3\\lib\\site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\mocha\\anaconda3\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\mocha\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\mocha\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\mocha\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\mocha\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mocha\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mocha\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mocha\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mocha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import defaultdict\n",
    "\n",
    "# NLP\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import emoji\n",
    "\n",
    "# Viz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139797f8",
   "metadata": {},
   "source": [
    "# Case Folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ca4a22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Buat fungsi untuk langkah case folding\n",
    "def casefolding(text):\n",
    "   # ubah text menjadi huruf kecil\n",
    "  text = text.lower()\n",
    "  # ubah enter menjadi spasi\n",
    "  text = re.sub(r'\\n', ' ', text)\n",
    "  # hapus emoji\n",
    "  text = emoji.demojize(text)\n",
    "  text = re.sub(':[A-Za-z_-]+:', ' ', text) # delete emoji\n",
    "  # hapus emoticon\n",
    "  text = re.sub(r\"([xX;:]'?[dDpPvVoO3)(])\", ' ', text)\n",
    "  # hapus link\n",
    "  text = re.sub(r\"(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})\", \"\", text)\n",
    "  # hapus usename\n",
    "  text = re.sub(r\"@[^\\s]+[\\s]?\", ' ', text)\n",
    "  # hapus hashtag\n",
    "  text = re.sub(r'#(\\S+)', r'\\1', text)\n",
    "  # hapus angka dan beberapa simbol\n",
    "  text = re.sub('[^a-zA-Z,.?!]+',' ',text)\n",
    "  # clear spasi\n",
    "  text = re.sub('[ ]+',' ',text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "704f8fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data\t:  Pertama benarkah harga air bersih lebih mahal dati minyak goreng?, migor paling murah 14 ribu??, \n",
      "Kedua anies guberbur bukan presiden, 18 tuntutan itu salah alamat kalau ke pemda DKI,!\n",
      "@detikcom  yg ngaco atau narasumber. https://t.co/m86erprJw7\n",
      "Case folding\t:  pertama benarkah harga air bersih lebih mahal dati minyak goreng?, migor paling murah ribu??, kedua anies guberbur bukan presiden, tuntutan itu salah alamat kalau ke pemda dki,! yg ngaco atau narasumber. \n"
     ]
    }
   ],
   "source": [
    "raw_sample = data['Text'].iloc[0]\n",
    "case_folding = casefolding(raw_sample)\n",
    "\n",
    "print('Raw data\\t: ', raw_sample)\n",
    "print('Case folding\\t: ', case_folding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c99278",
   "metadata": {},
   "source": [
    "# Word Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d39929d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 28, saw 411\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6364/2411401695.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkey_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://github.com/louisowen6/NLP_bahasa_resources/blob/master/combined_slang_words.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1248\u001b[0m             \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m                 \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1251\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m                 \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m                 \u001b[1;31m# destructive to chunks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 28, saw 411\n"
     ]
    }
   ],
   "source": [
    "key_norm = pd.read_csv('https://github.com/louisowen6/NLP_bahasa_resources/blob/master/combined_slang_words.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69126337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>singkat</th>\n",
       "      <th>hasil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>@</td>\n",
       "      <td>di</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>abis</td>\n",
       "      <td>habis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ad</td>\n",
       "      <td>ada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>adlh</td>\n",
       "      <td>adalah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>afaik</td>\n",
       "      <td>as far as i know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>NaN</td>\n",
       "      <td>wkwkkw</td>\n",
       "      <td>tertawa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ahokncc</td>\n",
       "      <td>ahok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>NaN</td>\n",
       "      <td>istaa</td>\n",
       "      <td>nista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>NaN</td>\n",
       "      <td>benarjujur</td>\n",
       "      <td>jujur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>NaN</td>\n",
       "      <td>mgkin</td>\n",
       "      <td>mungkin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1021 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      _id         singkat                 hasil\n",
       "0      NaN             @                   di  \n",
       "1      NaN          abis               habis   \n",
       "2      NaN            ad                  ada  \n",
       "3      NaN          adlh               adalah  \n",
       "4      NaN         afaik     as far as i know  \n",
       "...    ...            ...                   ...\n",
       "1016   NaN        wkwkkw             tertawa   \n",
       "1017   NaN       ahokncc                 ahok  \n",
       "1018   NaN         istaa                nista  \n",
       "1019   NaN    benarjujur                jujur  \n",
       "1020   NaN         mgkin               mungkin \n",
       "\n",
       "[1021 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_norm = pd.read_csv('combined_slang_words.txt')\n",
    "key_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8aa5ea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_norm['_id '] = np.arange(key_norm.shape[0])\n",
    "key_norm['_id ']= key_norm['_id '].astype(\"int32\")\n",
    "def add_1(x):\n",
    "    return x+1\n",
    "key_norm['_id '] = key_norm['_id '].add(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8622554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_id         int32\n",
      "singkat    object\n",
      " hasil     object\n",
      "dtype: object\n",
      "      _id         singkat                 hasil\n",
      "0        1             @                   di  \n",
      "1        2          abis               habis   \n",
      "2        3            ad                  ada  \n",
      "3        4          adlh               adalah  \n",
      "4        5         afaik     as far as i know  \n",
      "...    ...            ...                   ...\n",
      "1016  1017        wkwkkw             tertawa   \n",
      "1017  1018       ahokncc                 ahok  \n",
      "1018  1019         istaa                nista  \n",
      "1019  1020    benarjujur                jujur  \n",
      "1020  1021         mgkin               mungkin \n",
      "\n",
      "[1021 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(key_norm.dtypes)\n",
    "print(key_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d4e1b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#key_norm = pd.read_csv('https://github.com/louisowen6/NLP_bahasa_resources/blob/master/combined_slang_words.txt')\n",
    "\n",
    "def text_normalize(text):\n",
    "  text = ' '.join([key_norm[key_norm['singkat'] == word]['hasil'].values[0] if (key_norm['singkat'] == word).any() else word for word in text.split()])\n",
    "  text = str.lower(text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd62d04",
   "metadata": {},
   "source": [
    "# Filtering stopword removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e5ab1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords_ind = stopwords.words('indonesian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea47bb8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "758"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f6b0e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat fungsi untuk langkah stopword removal\n",
    "\n",
    "#more_stopword = ['barang','kirim']                    # Tambahkan kata dalam daftar stopword\n",
    "#stopwords_ind = stopwords_ind + more_stopword\n",
    "\n",
    "def remove_stop_words(text):\n",
    "  clean_words = []\n",
    "  text = text.split()\n",
    "  for word in text:\n",
    "      if word not in stopwords_ind:\n",
    "          clean_words.append(word)\n",
    "  return \" \".join(clean_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4095e0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data\t\t:  Pertama benarkah harga air bersih lebih mahal dati minyak goreng?, migor paling murah 14 ribu??, \n",
      "Kedua anies guberbur bukan presiden, 18 tuntutan itu salah alamat kalau ke pemda DKI,!\n",
      "@detikcom  yg ngaco atau narasumber. https://t.co/m86erprJw7\n",
      "Case folding\t\t:  pertama benarkah harga air bersih lebih mahal dati minyak goreng?, migor paling murah ribu??, kedua anies guberbur bukan presiden, tuntutan itu salah alamat kalau ke pemda dki,! yg ngaco atau narasumber. \n",
      "Stopword removal\t:  harga air bersih mahal dati minyak goreng?, migor murah ribu??, anies guberbur presiden, tuntutan salah alamat pemda dki,! yg ngaco narasumber.\n"
     ]
    }
   ],
   "source": [
    "raw_sample = data['Text'].iloc[0]\n",
    "case_folding = casefolding(raw_sample)\n",
    "stopword_removal = remove_stop_words(case_folding)\n",
    "\n",
    "print('Raw data\\t\\t: ', raw_sample)\n",
    "print('Case folding\\t\\t: ', case_folding)\n",
    "print('Stopword removal\\t: ', stopword_removal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb372f6",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "699a3a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "# Buat fungsi untuk langkah stemming bahasa Indonesia\n",
    "def stemming(text):\n",
    "  text = stemmer.stem(text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16f191ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data\t\t:  Pertama benarkah harga air bersih lebih mahal dati minyak goreng?, migor paling murah 14 ribu??, \n",
      "Kedua anies guberbur bukan presiden, 18 tuntutan itu salah alamat kalau ke pemda DKI,!\n",
      "@detikcom  yg ngaco atau narasumber. https://t.co/m86erprJw7\n",
      "Case folding\t\t:  pertama benarkah harga air bersih lebih mahal dati minyak goreng?, migor paling murah ribu??, kedua anies guberbur bukan presiden, tuntutan itu salah alamat kalau ke pemda dki,! yg ngaco atau narasumber. \n",
      "Stopword removal\t:  harga air bersih mahal dati minyak goreng?, migor murah ribu??, anies guberbur presiden, tuntutan salah alamat pemda dki,! yg ngaco narasumber.\n",
      "Stemming\t\t:  harga air bersih mahal dati minyak goreng migor murah ribu anies guberbur presiden tuntut salah alamat pemda dki yg ngaco narasumber\n"
     ]
    }
   ],
   "source": [
    "raw_sample = data['Text'].iloc[0]\n",
    "case_folding = casefolding(raw_sample)\n",
    "stopword_removal = remove_stop_words(case_folding)\n",
    "text_stemming = stemming(stopword_removal)\n",
    "\n",
    "print('Raw data\\t\\t: ', raw_sample)\n",
    "print('Case folding\\t\\t: ', case_folding)\n",
    "print('Stopword removal\\t: ', stopword_removal)\n",
    "print('Stemming\\t\\t: ', text_stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217ac690",
   "metadata": {},
   "source": [
    "# Text Preprcessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d49e567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat fungsi untuk menggabungkan seluruh langkah text preprocessing\n",
    "def text_preprocessing_process(text):\n",
    "  text = casefolding(text)\n",
    "  text = text_normalize(text)\n",
    "  text = remove_stop_words(text)\n",
    "  text = stemming(text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4564d080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 28min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['clean_teks'] = data['Text'].apply(text_preprocessing_process)\n",
    "\n",
    "# Perhatikan waktu komputasi ketika proses text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a468e002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Text</th>\n",
       "      <th>clean_teks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-14 23:47:33+00:00</td>\n",
       "      <td>Pertama benarkah harga air bersih lebih mahal ...</td>\n",
       "      <td>harga air bersih mahal dati minyak goreng migo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-14 23:40:21+00:00</td>\n",
       "      <td>Minyak goreng, dll kapan ya turun harga :') \\n...</td>\n",
       "      <td>minyak goreng dll ya turun harga terkejoet lho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-14 23:20:52+00:00</td>\n",
       "      <td>@detikcom Turun kan harga minyak goreng uae pa</td>\n",
       "      <td>turun harga minyak goreng uae pa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-14 23:14:02+00:00</td>\n",
       "      <td>Berikut Strategi Supaya Harga Minyak Goreng Sa...</td>\n",
       "      <td>strategi harga minyak goreng sawit rp liter be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-14 22:48:49+00:00</td>\n",
       "      <td>@eg_nrs Selamat pagi Mih...\\n\\nMau tanya Mih,m...</td>\n",
       "      <td>selamat pagi mih mih mengapa harga minyak gore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77952</th>\n",
       "      <td>2020-01-03 08:03:37+00:00</td>\n",
       "      <td>Waw Promo Superindo Periode 3-5 Januari 2020, ...</td>\n",
       "      <td>waw promo superindo periode januari diskon per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77953</th>\n",
       "      <td>2020-01-02 14:40:33+00:00</td>\n",
       "      <td>Abis mandi udah make skincare siap tidur\\nBapa...</td>\n",
       "      <td>abis mandi udah make skincare tidur pulang baw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77954</th>\n",
       "      <td>2020-01-02 14:09:32+00:00</td>\n",
       "      <td>@bucinajateros @in_makiy @FOODFESS2 Ya, \\nharg...</td>\n",
       "      <td>ya harga minyak goreng liter gas kg sedap bung...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77955</th>\n",
       "      <td>2020-01-01 06:49:02+00:00</td>\n",
       "      <td>@Savianisaa Mahal bgt harga minyak goreng segi...</td>\n",
       "      <td>mahal bgt harga minyak goreng segitu sav beli ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77956</th>\n",
       "      <td>2020-01-01 04:27:02+00:00</td>\n",
       "      <td>1. Aku goreng daging dgn kunyit dlu. agak dh y...</td>\n",
       "      <td>goreng daging dgn kunyit dlu dh yellowish angk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77957 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Datetime  \\\n",
       "0      2022-05-14 23:47:33+00:00   \n",
       "1      2022-05-14 23:40:21+00:00   \n",
       "2      2022-05-14 23:20:52+00:00   \n",
       "3      2022-05-14 23:14:02+00:00   \n",
       "4      2022-05-14 22:48:49+00:00   \n",
       "...                          ...   \n",
       "77952  2020-01-03 08:03:37+00:00   \n",
       "77953  2020-01-02 14:40:33+00:00   \n",
       "77954  2020-01-02 14:09:32+00:00   \n",
       "77955  2020-01-01 06:49:02+00:00   \n",
       "77956  2020-01-01 04:27:02+00:00   \n",
       "\n",
       "                                                    Text  \\\n",
       "0      Pertama benarkah harga air bersih lebih mahal ...   \n",
       "1      Minyak goreng, dll kapan ya turun harga :') \\n...   \n",
       "2         @detikcom Turun kan harga minyak goreng uae pa   \n",
       "3      Berikut Strategi Supaya Harga Minyak Goreng Sa...   \n",
       "4      @eg_nrs Selamat pagi Mih...\\n\\nMau tanya Mih,m...   \n",
       "...                                                  ...   \n",
       "77952  Waw Promo Superindo Periode 3-5 Januari 2020, ...   \n",
       "77953  Abis mandi udah make skincare siap tidur\\nBapa...   \n",
       "77954  @bucinajateros @in_makiy @FOODFESS2 Ya, \\nharg...   \n",
       "77955  @Savianisaa Mahal bgt harga minyak goreng segi...   \n",
       "77956  1. Aku goreng daging dgn kunyit dlu. agak dh y...   \n",
       "\n",
       "                                              clean_teks  \n",
       "0      harga air bersih mahal dati minyak goreng migo...  \n",
       "1      minyak goreng dll ya turun harga terkejoet lho...  \n",
       "2                       turun harga minyak goreng uae pa  \n",
       "3      strategi harga minyak goreng sawit rp liter be...  \n",
       "4      selamat pagi mih mih mengapa harga minyak gore...  \n",
       "...                                                  ...  \n",
       "77952  waw promo superindo periode januari diskon per...  \n",
       "77953  abis mandi udah make skincare tidur pulang baw...  \n",
       "77954  ya harga minyak goreng liter gas kg sedap bung...  \n",
       "77955  mahal bgt harga minyak goreng segitu sav beli ...  \n",
       "77956  goreng daging dgn kunyit dlu dh yellowish angk...  \n",
       "\n",
       "[77957 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3535ca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpan data yang telah melalui text preprocessing agar kita tidak perlu menjalankan proses tersebut mulai awal (Opsional)\n",
    "data.to_csv('clean_data_preprocessing_Proyek akhir11.csv')\n",
    "#data = pd.read_csv('clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c08229",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
